# Copy this file to `.env` and adjust the values to match your environment.

# Required for OpenAI-based ingestion and RAG steps.
OPENAI_API_KEY=sk-your-key

# Toggle the LLM/embedding provider used across ingestion and RAG.
# Use `openai` or `gemini`, then fill the corresponding section below.
PROVIDER=openai

# Provider: OpenAI
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Provider: Gemini
GEMINI_API_KEY=your-gemini-api-key
GEMINI_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/
GEMINI_MODEL=gemini-2.5-flash
GEMINI_EMBEDDING_MODEL=gemini-embedding-001

# Qdrant connection (leave QDRANT_HOST empty to fall back to local `data/vectorstore`)
QDRANT_API_KEY=
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_HTTPS=false
QDRANT_COLLECTION=galactic_menu


# Optional overrides (defaults are derived from the repo layout)
# DATASET_ROOT=/home/cris/dp_test/test-tecnico-ai-engineer/Dataset
# SOLUTION_DATA_DIR=/home/cris/dp_test/solution/data
# VECTORSTORE_PATH=/home/cris/dp_test/solution/data/vectorstore
# CHUNK_MAX_CHARS=1200
